{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b1509c6-db2b-4d39-8245-ac1649d8028c",
   "metadata": {},
   "source": [
    "# Unit Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0194760-a671-4a70-a74e-0016885f3fcb",
   "metadata": {},
   "source": [
    "## What it is: Unit testing involves writing tests for small parts of your code, usually functions or methods, to ensure they work as expected. In ML projects, unit testing helps validate that individual components, like data processing functions, model training functions, and utility functions, are performing correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce793c5-3b86-41ab-a414-214070573236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_fill_missing_values: PASSED\n"
     ]
    }
   ],
   "source": [
    "#Unit Test for Data Preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    return df.fillna(df.median())\n",
    "\n",
    "def test_fill_missing_values():\n",
    "    data = {'A': [1, 2, np.nan, 4], 'B': [5, np.nan, np.nan, 8]}\n",
    "    df = pd.DataFrame(data)\n",
    "    filled_df = fill_missing_values(df)\n",
    "    \n",
    "    assert filled_df.isnull().sum().sum() == 0, \"There should be no missing values\"\n",
    "    assert filled_df.loc[2, 'A'] == 2, \"The missing value in column A should be filled with median (2)\"\n",
    "    assert filled_df.loc[1, 'B'] == 6.5, \"The missing value in column B should be filled with median (6.5)\"\n",
    "\n",
    "# Run the test\n",
    "try:\n",
    "    test_fill_missing_values()\n",
    "    print(\"test_fill_missing_values: PASSED\")\n",
    "except AssertionError as e:\n",
    "    print(f\"test_fill_missing_values: FAILED - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "500c3828-78e3-4190-a0ed-8df2bfba239a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_generate_polynomial_features: PASSED\n"
     ]
    }
   ],
   "source": [
    "#Unit Test for Feature Engineering\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "def generate_polynomial_features(data, degree):\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    return poly.fit_transform(data)\n",
    "\n",
    "def test_generate_polynomial_features():\n",
    "    data = np.array([[2, 3], [3, 4]])\n",
    "    poly_data = generate_polynomial_features(data, degree=2)\n",
    "    \n",
    "    expected_shape = (2, 6)  # 2 samples and 6 features (including bias term)\n",
    "    assert poly_data.shape == expected_shape, f\"Expected shape {expected_shape}, but got {poly_data.shape}\"\n",
    "    assert np.allclose(poly_data[0], [1, 2, 3, 4, 6, 9]), \"Generated polynomial features are incorrect\"\n",
    "\n",
    "# Run the test\n",
    "try:\n",
    "    test_generate_polynomial_features()\n",
    "    print(\"test_generate_polynomial_features: PASSED\")\n",
    "except AssertionError as e:\n",
    "    print(f\"test_generate_polynomial_features: FAILED - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1e782a1-e8a0-42b3-9d92-01dcb84b2264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train_linear_model: PASSED\n"
     ]
    }
   ],
   "source": [
    "#Unit Test for Model Training\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "def train_linear_model(X, y):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def test_train_linear_model():\n",
    "    X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "    y = np.array([2, 3, 4, 5])\n",
    "    model = train_linear_model(X, y)\n",
    "    \n",
    "    assert not np.all(model.coef_ == 0), \"Model coefficients should not all be zero after training\"\n",
    "    assert model.intercept_ != 0, \"Model intercept should not be zero after training\"\n",
    "\n",
    "# Run the test\n",
    "try:\n",
    "    test_train_linear_model()\n",
    "    print(\"test_train_linear_model: PASSED\")\n",
    "except AssertionError as e:\n",
    "    print(f\"test_train_linear_model: FAILED - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ff228e-1dec-454a-aab6-a572ead36659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_make_predictions: PASSED\n"
     ]
    }
   ],
   "source": [
    "#Unit Test for Model Prediction\n",
    "def make_predictions(model, X):\n",
    "    return model.predict(X)\n",
    "\n",
    "def test_make_predictions():\n",
    "    X_train = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "    y_train = np.array([2, 3, 4, 5])\n",
    "    model = train_linear_model(X_train, y_train)\n",
    "    \n",
    "    X_test = np.array([[5, 6]])\n",
    "    prediction = make_predictions(model, X_test)\n",
    "    \n",
    "    assert np.isclose(prediction, [6]), f\"Expected prediction [6], but got {prediction}\"\n",
    "\n",
    "# Run the test\n",
    "try:\n",
    "    test_make_predictions()\n",
    "    print(\"test_make_predictions: PASSED\")\n",
    "except AssertionError as e:\n",
    "    print(f\"test_make_predictions: FAILED - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "518e02ce-18a2-41a4-91a6-a9679b08b9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_calculate_mae: PASSED\n"
     ]
    }
   ],
   "source": [
    "#Unit Test for Evaluation Metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "def calculate_mae(y_true, y_pred):\n",
    "    return mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def test_calculate_mae():\n",
    "    y_true = np.array([2, 3, 4, 5])\n",
    "    y_pred = np.array([2.1, 2.9, 4.2, 4.8])\n",
    "    mae = calculate_mae(y_true, y_pred)\n",
    "    \n",
    "    assert np.isclose(mae, 0.15), f\"Expected MAE 0.15, but got {mae}\"\n",
    "\n",
    "# Run the test\n",
    "try:\n",
    "    test_calculate_mae()\n",
    "    print(\"test_calculate_mae: PASSED\")\n",
    "except AssertionError as e:\n",
    "    print(f\"test_calculate_mae: FAILED - {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6932ef8-3f14-443d-b40d-90586544e05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_nn_initialization: FAILED - Parameters should be initialized with mean 0\n"
     ]
    }
   ],
   "source": [
    "#Unit Test for Neural Network Initialization\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "def test_nn_initialization():\n",
    "    model = SimpleNN()\n",
    "    for param in model.parameters():\n",
    "        assert param.data.mean().item() == 0, \"Parameters should be initialized with mean 0\"\n",
    "        assert param.data.std().item() > 0, \"Parameters should have a non-zero standard deviation\"\n",
    "\n",
    "# Run the test\n",
    "try:\n",
    "    test_nn_initialization()\n",
    "    print(\"test_nn_initialization: PASSED\")\n",
    "except AssertionError as e:\n",
    "    print(f\"test_nn_initialization: FAILED - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bc09e23-cc13-4f30-8e85-ab720de23236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_split_data: PASSED\n"
     ]
    }
   ],
   "source": [
    "#Unit Test for Data Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "def test_split_data():\n",
    "    X = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n",
    "    y = np.array([1, 2, 3, 4, 5])\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "    assert len(X_train) == 4, \"Training set should contain 80% of data\"\n",
    "    assert len(X_test) == 1, \"Testing set should contain 20% of data\"\n",
    "    assert len(y_train) == 4, \"y_train should contain 80% of labels\"\n",
    "    assert len(y_test) == 1, \"y_test should contain 20% of labels\"\n",
    "\n",
    "# Run the test\n",
    "try:\n",
    "    test_split_data()\n",
    "    print(\"test_split_data: PASSED\")\n",
    "except AssertionError as e:\n",
    "    print(f\"test_split_data: FAILED - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebadd041-df5c-40c9-9ac1-3a664b12aaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_one_hot_encode: PASSED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhishek_Jaiswal\\AppData\\Local\\miniconda3\\envs\\mlenv\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Unit Test for One-Hot Encoding\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def one_hot_encode(df, columns):\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    encoded_columns = encoder.fit_transform(df[columns])\n",
    "    encoded_df = pd.DataFrame(encoded_columns, columns=encoder.get_feature_names_out(columns))\n",
    "    return pd.concat([df.drop(columns, axis=1), encoded_df], axis=1)\n",
    "\n",
    "def test_one_hot_encode():\n",
    "    data = {'color': ['red', 'blue', 'green'], 'value': [1, 2, 3]}\n",
    "    df = pd.DataFrame(data)\n",
    "    encoded_df = one_hot_encode(df, ['color'])\n",
    "\n",
    "    expected_columns = ['value', 'color_blue', 'color_green', 'color_red']\n",
    "    assert all(col in encoded_df.columns for col in expected_columns), \"Encoded columns are missing\"\n",
    "    assert encoded_df.shape[1] == 4, f\"Expected 4 columns, but got {encoded_df.shape[1]}\"\n",
    "\n",
    "# Run the test\n",
    "try:\n",
    "    test_one_hot_encode()\n",
    "    print(\"test_one_hot_encode: PASSED\")\n",
    "except AssertionError as e:\n",
    "    print(f\"test_one_hot_encode: FAILED - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba9b2cd9-018d-4b0d-8e60-66ecef303dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_save_load_model: PASSED\n"
     ]
    }
   ],
   "source": [
    "#Unit Test for Model Saving and Loading\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "def save_model(model, filename):\n",
    "    joblib.dump(model, filename)\n",
    "\n",
    "def load_model(filename):\n",
    "    return joblib.load(filename)\n",
    "\n",
    "def test_save_load_model():\n",
    "    model = LogisticRegression()\n",
    "    X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "    y = np.array([0, 1, 0, 1])\n",
    "    model.fit(X, y)\n",
    "\n",
    "    save_model(model, 'test_model.pkl')\n",
    "    loaded_model = load_model('test_model.pkl')\n",
    "\n",
    "    assert np.allclose(model.coef_, loaded_model.coef_), \"Loaded model coefficients should match original\"\n",
    "    assert model.intercept_ == loaded_model.intercept_, \"Loaded model intercept should match original\"\n",
    "\n",
    "# Run the test\n",
    "try:\n",
    "    test_save_load_model()\n",
    "    print(\"test_save_load_model: PASSED\")\n",
    "except AssertionError as e:\n",
    "    print(f\"test_save_load_model: FAILED - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2af54bc5-59d7-4e1f-8ddd-3f4311a8a259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_calculate_confusion_matrix: PASSED\n"
     ]
    }
   ],
   "source": [
    "#Unit Test for Confusion Matrix Calculation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def calculate_confusion_matrix(y_true, y_pred):\n",
    "    return confusion_matrix(y_true, y_pred)\n",
    "\n",
    "def test_calculate_confusion_matrix():\n",
    "    y_true = np.array([1, 0, 1, 0, 1, 0])\n",
    "    y_pred = np.array([1, 0, 0, 0, 1, 1])\n",
    "    cm = calculate_confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    expected_cm = np.array([[2, 1], [1, 2]])\n",
    "    assert np.array_equal(cm, expected_cm), f\"Expected {expected_cm}, but got {cm}\"\n",
    "\n",
    "# Run the test\n",
    "try:\n",
    "    test_calculate_confusion_matrix()\n",
    "    print(\"test_calculate_confusion_matrix: PASSED\")\n",
    "except AssertionError as e:\n",
    "    print(f\"test_calculate_confusion_matrix: FAILED - {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14682943-4b7c-47be-ba9a-474768e3e540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_normalize_data: PASSED\n"
     ]
    }
   ],
   "source": [
    "#Unit Test for Data Normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def normalize_data(X):\n",
    "    scaler = MinMaxScaler()\n",
    "    return scaler.fit_transform(X)\n",
    "\n",
    "def test_normalize_data():\n",
    "    X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "    normalized_X = normalize_data(X)\n",
    "\n",
    "    assert np.allclose(normalized_X.min(), 0), \"Normalized data should have a minimum of 0\"\n",
    "    assert np.allclose(normalized_X.max(), 1), \"Normalized data should have a maximum of 1\"\n",
    "\n",
    "# Run the test\n",
    "try:\n",
    "    test_normalize_data()\n",
    "    print(\"test_normalize_data: PASSED\")\n",
    "except AssertionError as e:\n",
    "    print(f\"test_normalize_data: FAILED - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58d48852-2f8f-417a-992b-a2f9440df6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_standardize_data: PASSED\n"
     ]
    }
   ],
   "source": [
    "#Unit Test for Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def standardize_data(X):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(X)\n",
    "\n",
    "def test_standardize_data():\n",
    "    X = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
    "    standardized_X = standardize_data(X)\n",
    "\n",
    "    assert np.isclose(standardized_X.mean(), 0), \"Standardized data should have a mean of 0\"\n",
    "    assert np.isclose(standardized_X.std(), 1), \"Standardized data should have a standard deviation of 1\"\n",
    "\n",
    "# Run the test\n",
    "try:\n",
    "    test_standardize_data()\n",
    "    print(\"test_standardize_data: PASSED\")\n",
    "except AssertionError as e:\n",
    "    print(f\"test_standardize_data: FAILED - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbce3c34-9412-4c62-be2b-f2b8ed97c361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e815d-d5bf-4eaa-a71f-6882b7fe09bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c58d6b4-b3b6-4640-88b0-5ec9bd0b40ba",
   "metadata": {},
   "source": [
    "# Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a116992-9ce0-410d-9861-570b6e81e398",
   "metadata": {},
   "source": [
    "## What it is: Profiling in the context of ML/DL projects involves analyzing the performance of your code, identifying bottlenecks, and optimizing resource usage such as CPU, GPU, and memory. Profiling helps you understand which parts of your code are consuming the most time or memory and can help you make decisions on where to focus optimization efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1cb8f05-c61b-41cc-8fcf-45aa7b660ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         201033 function calls (198325 primitive calls) in 44.744 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000   44.727   44.727 1897314723.py:14(train_model)\n",
      "        1    0.000    0.000   44.733   44.733 1897314723.py:19(main)\n",
      "        1    0.000    0.000    0.006    0.006 1897314723.py:8(load_data)\n",
      "     1153    0.001    0.000    0.008    0.000 <frozen abc>:117(__instancecheck__)\n",
      "  618/616    0.001    0.000    0.003    0.000 <frozen abc>:121(__subclasscheck__)\n",
      "      301    0.001    0.000    0.002    0.000 <frozen importlib._bootstrap>:405(parent)\n",
      "        1    0.011    0.011   44.744   44.744 <string>:1(<module>)\n",
      "        1    0.000    0.000    0.000    0.000 <string>:2(__eq__)\n",
      "      301    0.000    0.000    0.000    0.000 _array_api.py:12(_check_array_api_dispatch)\n",
      "      406    0.000    0.000    0.000    0.000 _array_api.py:170(_check_device_cpu)\n",
      "     2026    0.006    0.000    0.007    0.000 _array_api.py:227(__getattr__)\n",
      "      100    0.000    0.000    0.004    0.000 _array_api.py:243(astype)\n",
      "      406    0.001    0.000    0.002    0.000 _array_api.py:247(asarray)\n",
      "      101    0.001    0.000    0.060    0.001 _array_api.py:261(unique_values)\n",
      "      304    0.001    0.000    0.016    0.000 _array_api.py:282(isdtype)\n",
      "      608    0.002    0.000    0.005    0.000 _array_api.py:289(get_namespace)\n",
      "      304    0.002    0.000    0.008    0.000 _array_api.py:360(_asarray_with_order)\n",
      "      506    0.003    0.000    0.005    0.000 _array_api.py:70(_is_numpy_namespace)\n",
      "      304    0.002    0.000    0.015    0.000 _array_api.py:75(isdtype)\n",
      "      205    0.000    0.000    0.002    0.000 _array_api.py:82(<genexpr>)\n",
      "  507/305    0.007    0.000    0.012    0.000 _array_api.py:87(_isdtype_single)\n",
      "      303    0.001    0.000    0.007    0.000 _array_api.py:96(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 _base.py:122(__init__)\n",
      "     1010    0.001    0.000    0.002    0.000 _base.py:1335(issparse)\n",
      "        1    0.000    0.000    0.000    0.000 _base.py:141(_validate_estimator)\n",
      "      100    0.002    0.000    0.255    0.003 _base.py:181(_make_estimator)\n",
      "      100    0.001    0.000    0.001    0.000 _base.py:188(<dictcomp>)\n",
      "      100    0.003    0.000    0.098    0.001 _base.py:40(_set_random_states)\n",
      "      101    0.000    0.000    0.000    0.000 _classes.py:127(__init__)\n",
      "      100    0.034    0.000   44.246    0.442 _classes.py:221(_fit)\n",
      "      100    0.001    0.000    0.011    0.000 _classes.py:580(_prune_tree)\n",
      "      101    0.001    0.000    0.001    0.000 _classes.py:897(__init__)\n",
      "      100    0.009    0.000   44.255    0.443 _classes.py:928(fit)\n",
      "      402    0.003    0.000    0.016    0.000 _config.py:196(config_context)\n",
      "     1415    0.003    0.000    0.004    0.000 _config.py:24(_get_threadlocal_config)\n",
      "     1013    0.003    0.000    0.006    0.000 _config.py:32(get_config)\n",
      "      402    0.009    0.000    0.012    0.000 _config.py:50(set_config)\n",
      "      100    0.001    0.000    0.137    0.001 _forest.py:127(_generate_sample_indices)\n",
      "        1    0.000    0.000    0.000    0.000 _forest.py:1395(__init__)\n",
      "      100    0.020    0.000   44.438    0.444 _forest.py:151(_parallel_build_trees)\n",
      "        1    0.000    0.000    0.000    0.000 _forest.py:218(__init__)\n",
      "        1    0.000    0.000   44.725   44.725 _forest.py:317(fit)\n",
      "        1    0.000    0.000    0.255    0.255 _forest.py:445(<listcomp>)\n",
      "      101    0.002    0.000    0.010    0.000 _forest.py:460(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 _forest.py:664(__init__)\n",
      "        1    0.000    0.000    0.002    0.002 _forest.py:748(_validate_y_class_weight)\n",
      "        1    0.000    0.000    0.000    0.000 _forest.py:94(_get_n_samples_bootstrap)\n",
      "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:106(compute_batch_size)\n",
      "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:219(effective_n_jobs)\n",
      "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:246(effective_n_jobs)\n",
      "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:321(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 _parallel_backends.py:43(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:432(configure)\n",
      "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:642(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _parallel_backends.py:87(configure)\n",
      "    34/33    0.000    0.000    0.000    0.000 _param_validation.py:101(make_constraint)\n",
      "       31    0.000    0.000    0.000    0.000 _param_validation.py:257(__init__)\n",
      "        1    0.000    0.000    0.001    0.001 _param_validation.py:26(validate_parameter_constraints)\n",
      "       16    0.000    0.000    0.000    0.000 _param_validation.py:289(__init__)\n",
      "        7    0.000    0.000    0.000    0.000 _param_validation.py:293(is_satisfied_by)\n",
      "        6    0.000    0.000    0.000    0.000 _param_validation.py:303(is_satisfied_by)\n",
      "        3    0.000    0.000    0.000    0.000 _param_validation.py:359(is_satisfied_by)\n",
      "        2    0.000    0.000    0.000    0.000 _param_validation.py:429(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 _param_validation.py:438(_check_params)\n",
      "        7    0.000    0.000    0.000    0.000 _param_validation.py:477(__contains__)\n",
      "       12    0.000    0.000    0.000    0.000 _param_validation.py:493(is_satisfied_by)\n",
      "        1    0.000    0.000    0.000    0.000 _param_validation.py:555(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _param_validation.py:563(is_satisfied_by)\n",
      "        4    0.000    0.000    0.000    0.000 _param_validation.py:564(<genexpr>)\n",
      "        3    0.000    0.000    0.000    0.000 _param_validation.py:580(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 _param_validation.py:588(is_satisfied_by)\n",
      "        6    0.000    0.000    0.000    0.000 _param_validation.py:599(<genexpr>)\n",
      "        1    0.000    0.000    0.000    0.000 _param_validation.py:615(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 _param_validation.py:623(is_satisfied_by)\n",
      "        2    0.000    0.000    0.000    0.000 _param_validation.py:624(<genexpr>)\n",
      "       18    0.000    0.000    0.001    0.000 _param_validation.py:72(<listcomp>)\n",
      "      602    0.004    0.000    0.004    0.000 _ufunc_config.py:132(geterr)\n",
      "      602    0.005    0.000    0.012    0.000 _ufunc_config.py:33(seterr)\n",
      "      101    0.000    0.000    0.000    0.000 _ufunc_config.py:426(__init__)\n",
      "      301    0.002    0.000    0.010    0.000 _ufunc_config.py:430(__enter__)\n",
      "      301    0.001    0.000    0.006    0.000 _ufunc_config.py:435(__exit__)\n",
      "      203    0.000    0.000    0.001    0.000 arraysetops.py:125(_unpack_tuple)\n",
      "      203    0.000    0.000    0.000    0.000 arraysetops.py:133(_unique_dispatcher)\n",
      "      203    0.003    0.000    0.166    0.001 arraysetops.py:138(unique)\n",
      "      203    0.044    0.000    0.163    0.001 arraysetops.py:323(_unique1d)\n",
      "      300    0.001    0.000    0.002    0.000 base.py:1062(is_classifier)\n",
      "    101/1    0.003    0.000   44.727   44.727 base.py:1135(wrapper)\n",
      "      501    0.012    0.000    0.202    0.000 base.py:147(_get_param_names)\n",
      "      501    0.015    0.000    0.020    0.000 base.py:161(<listcomp>)\n",
      "      501    0.006    0.000    0.008    0.000 base.py:176(<listcomp>)\n",
      "      501    0.011    0.000    0.216    0.000 base.py:178(get_params)\n",
      "      200    0.005    0.000    0.094    0.000 base.py:202(set_params)\n",
      "      100    0.000    0.000    0.105    0.001 base.py:267(__sklearn_clone__)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:374(_check_n_features)\n",
      " 1300/100    0.003    0.000    0.106    0.001 base.py:40(clone)\n",
      "        1    0.000    0.000    0.000    0.000 base.py:420(_check_feature_names)\n",
      "        1    0.000    0.000    0.003    0.003 base.py:509(_validate_data)\n",
      "        1    0.000    0.000    0.002    0.002 base.py:630(_validate_params)\n",
      " 1300/100    0.010    0.000    0.105    0.001 base.py:79(_clone_parametrized)\n",
      "        1    0.000    0.000    0.000    0.000 context.py:237(get_context)\n",
      "      201    0.002    0.000    0.002    0.000 contextlib.py:104(__init__)\n",
      "      201    0.001    0.000    0.006    0.000 contextlib.py:132(__enter__)\n",
      "      201    0.002    0.000    0.013    0.000 contextlib.py:141(__exit__)\n",
      "      201    0.001    0.000    0.003    0.000 contextlib.py:287(helper)\n",
      "      200    0.000    0.000    0.000    0.000 contextlib.py:65(_recreate_cm)\n",
      "        1    0.000    0.000    0.000    0.000 contextlib.py:751(__init__)\n",
      "      200    0.002    0.000    0.068    0.000 contextlib.py:78(inner)\n",
      "     1200    0.005    0.000    0.007    0.000 copy.py:128(deepcopy)\n",
      "     1200    0.000    0.000    0.000    0.000 copy.py:182(_deepcopy_atomic)\n",
      "        1    0.000    0.000    0.000    0.000 disk.py:42(memstr_to_bytes)\n",
      "     6519    0.005    0.000    0.005    0.000 enum.py:1091(__new__)\n",
      "     6519    0.011    0.000    0.016    0.000 enum.py:685(__call__)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:195(_reshape_dispatcher)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:200(reshape)\n",
      "      201    0.000    0.000    0.000    0.000 fromnumeric.py:2172(_sum_dispatcher)\n",
      "      201    0.001    0.000    0.010    0.000 fromnumeric.py:2177(sum)\n",
      "      100    0.000    0.000    0.000    0.000 fromnumeric.py:2317(_any_dispatcher)\n",
      "      100    0.001    0.000    0.004    0.000 fromnumeric.py:2322(any)\n",
      "      101    0.000    0.000    0.000    0.000 fromnumeric.py:2508(_cumsum_dispatcher)\n",
      "      101    0.001    0.000    0.010    0.000 fromnumeric.py:2512(cumsum)\n",
      "      100    0.000    0.000    0.000    0.000 fromnumeric.py:2687(_max_dispatcher)\n",
      "      100    0.000    0.000    0.003    0.000 fromnumeric.py:2692(max)\n",
      "      101    0.000    0.000    0.000    0.000 fromnumeric.py:2974(_prod_dispatcher)\n",
      "      101    0.001    0.000    0.008    0.000 fromnumeric.py:2979(prod)\n",
      "      102    0.000    0.000    0.009    0.000 fromnumeric.py:53(_wrapfunc)\n",
      "      502    0.005    0.000    0.022    0.000 fromnumeric.py:71(_wrapreduction)\n",
      "      502    0.002    0.000    0.002    0.000 fromnumeric.py:72(<dictcomp>)\n",
      "      101    0.000    0.000    0.000    0.000 function_base.py:869(_copy_dispatcher)\n",
      "      101    0.000    0.000    0.002    0.000 function_base.py:873(copy)\n",
      "      200    0.003    0.000    0.005    0.000 functools.py:35(update_wrapper)\n",
      "      100    0.001    0.000    0.001    0.000 functools.py:65(wraps)\n",
      "      200    0.003    0.000    0.003    0.000 getlimits.py:685(__init__)\n",
      "      200    0.001    0.000    0.001    0.000 getlimits.py:709(max)\n",
      "      501    0.003    0.000    0.004    0.000 inspect.py:167(get_annotations)\n",
      "      501    0.042    0.000    0.141    0.000 inspect.py:2333(_signature_from_function)\n",
      "      501    0.009    0.000    0.156    0.000 inspect.py:2428(_signature_from_callable)\n",
      "     6519    0.041    0.000    0.065    0.000 inspect.py:2686(__init__)\n",
      "    19056    0.007    0.000    0.007    0.000 inspect.py:2739(name)\n",
      "    12036    0.004    0.000    0.004    0.000 inspect.py:2751(kind)\n",
      "      200    0.001    0.000    0.001    0.000 inspect.py:292(isclass)\n",
      "      501    0.010    0.000    0.022    0.000 inspect.py:2972(__init__)\n",
      "     7020    0.009    0.000    0.012    0.000 inspect.py:3019(<genexpr>)\n",
      "      501    0.001    0.000    0.157    0.000 inspect.py:3024(from_callable)\n",
      "      501    0.000    0.000    0.000    0.000 inspect.py:3032(parameters)\n",
      "      501    0.001    0.000    0.158    0.000 inspect.py:3278(signature)\n",
      "     1002    0.001    0.000    0.001    0.000 inspect.py:378(isfunction)\n",
      "      501    0.002    0.000    0.004    0.000 inspect.py:735(unwrap)\n",
      "      501    0.001    0.000    0.001    0.000 inspect.py:755(_is_wrapper)\n",
      "        1    0.000    0.000    0.000    0.000 logger.py:67(__init__)\n",
      "      100    0.000    0.000    0.000    0.000 multiarray.py:1080(copyto)\n",
      "      200    0.000    0.000    0.000    0.000 multiarray.py:153(concatenate)\n",
      "      100    0.000    0.000    0.000    0.000 multiarray.py:892(bincount)\n",
      "      101    0.004    0.000    0.021    0.000 multiclass.py:124(is_multilabel)\n",
      "      101    0.001    0.000    0.122    0.001 multiclass.py:196(check_classification_targets)\n",
      "      101    0.014    0.000    0.121    0.001 multiclass.py:223(type_of_target)\n",
      "      100    0.005    0.000    0.008    0.000 numeric.py:136(ones)\n",
      "      100    0.000    0.000    0.002    0.000 parallel.py:105(__init__)\n",
      "      100    0.000    0.000    0.000    0.000 parallel.py:109(with_config)\n",
      "       12    0.000    0.000    0.000    0.000 parallel.py:110(_get_config_param)\n",
      "      100    0.003    0.000   44.449    0.444 parallel.py:113(__call__)\n",
      "        1    0.000    0.000    0.001    0.001 parallel.py:1176(__init__)\n",
      "      100    0.000    0.000    0.001    0.000 parallel.py:12(_with_config)\n",
      "        1    0.000    0.000    0.000    0.000 parallel.py:1219(<dictcomp>)\n",
      "      2/1    0.000    0.000    0.000    0.000 parallel.py:1329(_initialize_backend)\n",
      "        1    0.000    0.000    0.000    0.000 parallel.py:142(_get_active_backend)\n",
      "        1    0.000    0.000    0.000    0.000 parallel.py:1465(_get_batch_size)\n",
      "      101    0.000    0.000    0.000    0.000 parallel.py:1491(print_progress)\n",
      "      102    0.003    0.000   44.463    0.436 parallel.py:1764(_get_sequential_output)\n",
      "        1    0.000    0.000    0.000    0.000 parallel.py:1808(_reset_run_tracking)\n",
      "        1    0.000    0.000   44.464   44.464 parallel.py:1847(__call__)\n",
      "        1    0.000    0.000   44.464   44.464 parallel.py:42(__call__)\n",
      "      101    0.001    0.000    0.011    0.000 parallel.py:61(<genexpr>)\n",
      "      100    0.001    0.000    0.005    0.000 parallel.py:69(delayed)\n",
      "      100    0.001    0.000    0.003    0.000 parallel.py:95(delayed_function)\n",
      "        1    0.000    0.000    0.000    0.000 queue.py:206(_init)\n",
      "        1    0.000    0.000    0.000    0.000 queue.py:34(__init__)\n",
      "      200    0.002    0.000    0.004    0.000 random.py:800(getrandbits)\n",
      "      101    0.000    0.000    0.000    0.000 shape_base.py:19(_atleast_1d_dispatcher)\n",
      "      101    0.001    0.000    0.001    0.000 shape_base.py:23(atleast_1d)\n",
      "        3    0.000    0.000    0.000    0.000 threading.py:236(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 threading.py:90(RLock)\n",
      "        1    0.000    0.000    0.000    0.000 uuid.py:139(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 uuid.py:334(hex)\n",
      "        1    0.000    0.000    0.000    0.000 uuid.py:721(uuid4)\n",
      "        1    0.000    0.000    0.003    0.003 validation.py:1020(check_X_y)\n",
      "        1    0.000    0.000    0.000    0.000 validation.py:1169(_check_y)\n",
      "      301    0.069    0.000    0.146    0.000 validation.py:1249(check_random_state)\n",
      "      100    0.001    0.000    0.007    0.000 validation.py:1366(_is_fitted)\n",
      "      100    0.003    0.000    0.005    0.000 validation.py:1398(<listcomp>)\n",
      "      100    0.001    0.000    0.010    0.000 validation.py:1404(check_is_fitted)\n",
      "      100    0.002    0.000    0.055    0.001 validation.py:1787(_check_sample_weight)\n",
      "        1    0.000    0.000    0.000    0.000 validation.py:1987(_get_feature_names)\n",
      "        1    0.000    0.000    0.000    0.000 validation.py:277(_num_features)\n",
      "      204    0.003    0.000    0.006    0.000 validation.py:330(_num_samples)\n",
      "        1    0.000    0.000    0.000    0.000 validation.py:393(check_consistent_length)\n",
      "        1    0.000    0.000    0.000    0.000 validation.py:404(<listcomp>)\n",
      "      304    0.001    0.000    0.001    0.000 validation.py:581(_ensure_no_complex_data)\n",
      "      304    0.000    0.000    0.000    0.000 validation.py:591(_check_estimator_name)\n",
      "      304    0.001    0.000    0.001    0.000 validation.py:639(_is_extension_array_dtype)\n",
      "      304    0.013    0.000    0.073    0.000 validation.py:644(check_array)\n",
      "      102    0.006    0.000    0.023    0.000 validation.py:92(_assert_all_finite)\n",
      "      506    0.002    0.000    0.007    0.000 warnings.py:165(simplefilter)\n",
      "      506    0.003    0.000    0.005    0.000 warnings.py:181(_add_filter)\n",
      "      506    0.001    0.000    0.001    0.000 warnings.py:440(__init__)\n",
      "      506    0.003    0.000    0.003    0.000 warnings.py:466(__enter__)\n",
      "      506    0.002    0.000    0.002    0.000 warnings.py:487(__exit__)\n",
      "     1153    0.004    0.000    0.007    0.000 {built-in method _abc._abc_instancecheck}\n",
      "  618/616    0.002    0.000    0.002    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "        6    0.000    0.000    0.000    0.000 {built-in method _operator.ge}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _operator.gt}\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method _operator.lt}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "     1518    0.001    0.000    0.001    0.000 {built-in method _warnings._filters_mutated}\n",
      "      208    0.001    0.000    0.010    0.000 {built-in method builtins.any}\n",
      "     1002    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        1    0.000    0.000   44.744   44.744 {built-in method builtins.exec}\n",
      "    13661    0.008    0.000    0.008    0.000 {built-in method builtins.getattr}\n",
      "    11973    0.007    0.000    0.007    0.000 {built-in method builtins.hasattr}\n",
      "     1701    0.001    0.000    0.001    0.000 {built-in method builtins.id}\n",
      "    15369    0.008    0.000    0.016    0.000 {built-in method builtins.isinstance}\n",
      "      914    0.001    0.000    0.001    0.000 {built-in method builtins.len}\n",
      "      201    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "      101    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "      403    0.001    0.000    0.017    0.000 {built-in method builtins.next}\n",
      "     2100    0.001    0.000    0.001    0.000 {built-in method builtins.setattr}\n",
      "      601    0.002    0.000    0.002    0.000 {built-in method builtins.sorted}\n",
      "      100    0.001    0.000    0.001    0.000 {built-in method builtins.vars}\n",
      "      201    0.000    0.000    0.000    0.000 {built-in method from_bytes}\n",
      "      201    0.001    0.000    0.001    0.000 {built-in method nt.urandom}\n",
      "      201    0.002    0.000    0.002    0.000 {built-in method numpy.array}\n",
      "      507    0.000    0.000    0.000    0.000 {built-in method numpy.asanyarray}\n",
      "      710    0.002    0.000    0.002    0.000 {built-in method numpy.asarray}\n",
      "      101    0.002    0.000    0.002    0.000 {built-in method numpy.ascontiguousarray}\n",
      "      404    0.003    0.000    0.003    0.000 {built-in method numpy.empty}\n",
      "     1204    0.001    0.000    0.001    0.000 {built-in method numpy.geterrobj}\n",
      "      602    0.002    0.000    0.002    0.000 {built-in method numpy.seterrobj}\n",
      "      101    0.001    0.000    0.001    0.000 {built-in method numpy.zeros}\n",
      "      501    0.000    0.000    0.000    0.000 {built-in method sys.getrecursionlimit}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "      200    0.056    0.000    0.056    0.000 {function SeedSequence.generate_state at 0x00000261637114E0}\n",
      "     6519    0.003    0.000    0.003    0.000 {method '__contains__' of 'frozenset' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "     6822    0.003    0.000    0.003    0.000 {method 'append' of 'list' objects}\n",
      "      101    0.057    0.001    0.057    0.001 {method 'argsort' of 'numpy.ndarray' objects}\n",
      "      100    0.004    0.000    0.004    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "      100   43.834    0.438   43.834    0.438 {method 'build' of 'sklearn.tree._tree.DepthFirstTreeBuilder' objects}\n",
      "     1014    0.001    0.000    0.001    0.000 {method 'copy' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'count' of 'list' objects}\n",
      "      101    0.009    0.000    0.009    0.000 {method 'cumsum' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "     2900    0.002    0.000    0.002    0.000 {method 'endswith' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'extend' of 'list' objects}\n",
      "      203    0.003    0.000    0.003    0.000 {method 'flatten' of 'numpy.ndarray' objects}\n",
      "    15438    0.005    0.000    0.005    0.000 {method 'get' of 'dict' objects}\n",
      "      506    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
      "     6519    0.003    0.000    0.003    0.000 {method 'isidentifier' of 'str' objects}\n",
      "     1003    0.001    0.000    0.001    0.000 {method 'items' of 'dict' objects}\n",
      "     1100    0.001    0.000    0.001    0.000 {method 'partition' of 'str' objects}\n",
      "        1    0.005    0.005    0.005    0.005 {method 'rand' of 'numpy.random.mtrand.RandomState' objects}\n",
      "      201    0.052    0.000    0.060    0.000 {method 'randint' of 'numpy.random.mtrand.RandomState' objects}\n",
      "      502    0.014    0.000    0.014    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "      506    0.001    0.000    0.001    0.000 {method 'remove' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "      301    0.001    0.000    0.001    0.000 {method 'rpartition' of 'str' objects}\n",
      "      102    0.049    0.000    0.049    0.000 {method 'sort' of 'numpy.ndarray' objects}\n",
      "      600    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "      200    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "      501    0.000    0.000    0.000    0.000 {method 'values' of 'mappingproxy' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Profiling with cProfile\n",
    "#cProfile is a built-in Python module that provides a detailed report of function calls, including time spent in each function.\n",
    "\n",
    "import cProfile\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def load_data():\n",
    "    # Simulate loading data\n",
    "    X = np.random.rand(10000, 20)\n",
    "    y = np.random.randint(0, 2, 10000)\n",
    "    return X, y\n",
    "\n",
    "def train_model(X, y):\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    X, y = load_data()\n",
    "    model = train_model(X, y)\n",
    "\n",
    "# Profile the main function\n",
    "cProfile.run('main()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80c58096-b396-4b9e-bee5-8004d8adc01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find file C:\\Users\\Abhishek_Jaiswal\\AppData\\Local\\Temp\\ipykernel_32472\\4197188316.py\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>col_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.239438</td>\n",
       "      <td>0.527816</td>\n",
       "      <td>0.473308</td>\n",
       "      <td>0.769237</td>\n",
       "      <td>0.072831</td>\n",
       "      <td>0.581874</td>\n",
       "      <td>0.326494</td>\n",
       "      <td>0.891716</td>\n",
       "      <td>0.205090</td>\n",
       "      <td>0.124340</td>\n",
       "      <td>4.212145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.246050</td>\n",
       "      <td>0.054724</td>\n",
       "      <td>0.506426</td>\n",
       "      <td>0.020357</td>\n",
       "      <td>0.089198</td>\n",
       "      <td>0.137109</td>\n",
       "      <td>0.393631</td>\n",
       "      <td>0.900328</td>\n",
       "      <td>0.108786</td>\n",
       "      <td>0.569204</td>\n",
       "      <td>3.025811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.843365</td>\n",
       "      <td>0.038258</td>\n",
       "      <td>0.627765</td>\n",
       "      <td>0.445383</td>\n",
       "      <td>0.559283</td>\n",
       "      <td>0.912020</td>\n",
       "      <td>0.836728</td>\n",
       "      <td>0.756270</td>\n",
       "      <td>0.656609</td>\n",
       "      <td>0.977788</td>\n",
       "      <td>6.653469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.301246</td>\n",
       "      <td>0.194494</td>\n",
       "      <td>0.909902</td>\n",
       "      <td>0.966589</td>\n",
       "      <td>0.584935</td>\n",
       "      <td>0.689754</td>\n",
       "      <td>0.260273</td>\n",
       "      <td>0.135848</td>\n",
       "      <td>0.384984</td>\n",
       "      <td>0.471336</td>\n",
       "      <td>4.899361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.674663</td>\n",
       "      <td>0.206842</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.160282</td>\n",
       "      <td>0.134196</td>\n",
       "      <td>0.177756</td>\n",
       "      <td>0.776780</td>\n",
       "      <td>0.560751</td>\n",
       "      <td>0.784129</td>\n",
       "      <td>0.259443</td>\n",
       "      <td>3.737334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0.554016</td>\n",
       "      <td>0.063069</td>\n",
       "      <td>0.464241</td>\n",
       "      <td>0.482893</td>\n",
       "      <td>0.759817</td>\n",
       "      <td>0.194917</td>\n",
       "      <td>0.938976</td>\n",
       "      <td>0.485525</td>\n",
       "      <td>0.653090</td>\n",
       "      <td>0.497936</td>\n",
       "      <td>5.094481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>0.044191</td>\n",
       "      <td>0.576465</td>\n",
       "      <td>0.643956</td>\n",
       "      <td>0.644571</td>\n",
       "      <td>0.993955</td>\n",
       "      <td>0.250678</td>\n",
       "      <td>0.098439</td>\n",
       "      <td>0.858626</td>\n",
       "      <td>0.049913</td>\n",
       "      <td>0.784549</td>\n",
       "      <td>4.945345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0.711333</td>\n",
       "      <td>0.835933</td>\n",
       "      <td>0.319238</td>\n",
       "      <td>0.858734</td>\n",
       "      <td>0.815850</td>\n",
       "      <td>0.603493</td>\n",
       "      <td>0.591752</td>\n",
       "      <td>0.498782</td>\n",
       "      <td>0.959497</td>\n",
       "      <td>0.772368</td>\n",
       "      <td>6.966978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>0.676477</td>\n",
       "      <td>0.677218</td>\n",
       "      <td>0.977506</td>\n",
       "      <td>0.723864</td>\n",
       "      <td>0.322024</td>\n",
       "      <td>0.987257</td>\n",
       "      <td>0.857471</td>\n",
       "      <td>0.901892</td>\n",
       "      <td>0.593534</td>\n",
       "      <td>0.919762</td>\n",
       "      <td>7.637005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0.347356</td>\n",
       "      <td>0.342984</td>\n",
       "      <td>0.238076</td>\n",
       "      <td>0.038066</td>\n",
       "      <td>0.219112</td>\n",
       "      <td>0.567619</td>\n",
       "      <td>0.325376</td>\n",
       "      <td>0.649793</td>\n",
       "      <td>0.631211</td>\n",
       "      <td>0.231217</td>\n",
       "      <td>3.590810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
       "0       0.239438  0.527816  0.473308  0.769237  0.072831  0.581874  0.326494   \n",
       "1       0.246050  0.054724  0.506426  0.020357  0.089198  0.137109  0.393631   \n",
       "2       0.843365  0.038258  0.627765  0.445383  0.559283  0.912020  0.836728   \n",
       "3       0.301246  0.194494  0.909902  0.966589  0.584935  0.689754  0.260273   \n",
       "4       0.674663  0.206842  0.002493  0.160282  0.134196  0.177756  0.776780   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "999995  0.554016  0.063069  0.464241  0.482893  0.759817  0.194917  0.938976   \n",
       "999996  0.044191  0.576465  0.643956  0.644571  0.993955  0.250678  0.098439   \n",
       "999997  0.711333  0.835933  0.319238  0.858734  0.815850  0.603493  0.591752   \n",
       "999998  0.676477  0.677218  0.977506  0.723864  0.322024  0.987257  0.857471   \n",
       "999999  0.347356  0.342984  0.238076  0.038066  0.219112  0.567619  0.325376   \n",
       "\n",
       "           col_7     col_8     col_9   col_sum  \n",
       "0       0.891716  0.205090  0.124340  4.212145  \n",
       "1       0.900328  0.108786  0.569204  3.025811  \n",
       "2       0.756270  0.656609  0.977788  6.653469  \n",
       "3       0.135848  0.384984  0.471336  4.899361  \n",
       "4       0.560751  0.784129  0.259443  3.737334  \n",
       "...          ...       ...       ...       ...  \n",
       "999995  0.485525  0.653090  0.497936  5.094481  \n",
       "999996  0.858626  0.049913  0.784549  4.945345  \n",
       "999997  0.498782  0.959497  0.772368  6.966978  \n",
       "999998  0.901892  0.593534  0.919762  7.637005  \n",
       "999999  0.649793  0.631211  0.231217  3.590810  \n",
       "\n",
       "[1000000 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Memory Profiling with memory_profiler\n",
    "#Memory profiling helps you understand how much memory is being used by different parts of your code, which is especially important in DL projects where large models and datasets are involved.\n",
    "\n",
    "from memory_profiler import profile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "@profile\n",
    "def data_preprocessing():\n",
    "    # Simulate a large dataset\n",
    "    df = pd.DataFrame(np.random.rand(1000000, 10), columns=[f'col_{i}' for i in range(10)])\n",
    "    \n",
    "    # Preprocessing: Filling missing values\n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "    \n",
    "    # More preprocessing steps...\n",
    "    df['col_sum'] = df.sum(axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run the function to profile\n",
    "data_preprocessing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87bcace-7d64-476f-aae1-96c1aa5ff9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU Profiling with torch.cuda\n",
    "#In deep learning, GPU profiling is crucial for understanding GPU utilization, memory consumption, and the time spent on different operations. PyTorch provides some basic tools for this.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "def train_model():\n",
    "    model = SimpleModel().cuda()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Simulate input data\n",
    "    inputs = torch.randn(64, 1024).cuda()\n",
    "    labels = torch.randint(0, 10, (64,)).cuda()\n",
    "    \n",
    "    # Training loop\n",
    "    start_time = time.time()\n",
    "    for _ in range(100):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Run the function\n",
    "train_model()\n",
    "\n",
    "# GPU memory profiling\n",
    "print(f\"Max GPU memory allocated: {torch.cuda.max_memory_allocated() / 1024**2:.2f} MiB\")\n",
    "print(f\"Max GPU memory cached: {torch.cuda.max_memory_reserved() / 1024**2:.2f} MiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64c01000-d61f-4aa4-b04c-ac662640d730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average execution time over 100 runs: 0.11175 seconds\n"
     ]
    }
   ],
   "source": [
    "#Time Profiling with timeit\n",
    "#timeit is a simple way to profile the execution time of small code snippets.\n",
    "\n",
    "import timeit\n",
    "\n",
    "def example_function():\n",
    "    sum(range(1000000))\n",
    "\n",
    "# Time profiling\n",
    "execution_time = timeit.timeit('example_function()', globals=globals(), number=100)\n",
    "print(f\"Average execution time over 100 runs: {execution_time / 100:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2747ff0d-d687-4b8b-96e2-09ed0b6fbacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 0.0509071 s\n",
      "\n",
      "Could not find file C:\\Users\\Abhishek_Jaiswal\\AppData\\Local\\Temp\\ipykernel_32472\\173877596.py\n",
      "Are you sure you are running this program from the same directory\n",
      "that you ran the profiler from?\n",
      "Continuing without the function's contents.\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    15                                           \n",
      "    16         1     492885.0 492885.0     96.8  \n",
      "    17         1       8818.0   8818.0      1.7  \n",
      "    18         1       7368.0   7368.0      1.4  \n",
      "\n",
      "Total time: 0.0870728 s\n",
      "\n",
      "Could not find file C:\\Users\\Abhishek_Jaiswal\\AppData\\Local\\Temp\\ipykernel_32472\\173877596.py\n",
      "Are you sure you are running this program from the same directory\n",
      "that you ran the profiler from?\n",
      "Continuing without the function's contents.\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    20                                           \n",
      "    21         1     238933.0 238933.0     27.4  \n",
      "    22         1     118900.0 118900.0     13.7  \n",
      "    23         1     512895.0 512895.0     58.9  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Profiling with line_profiler\n",
    "#line_profiler provides more granular control by allowing you to profile individual functions line by line.\n",
    "\n",
    "from line_profiler import LineProfiler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "def profile_model():\n",
    "    model = SimpleNN()\n",
    "    inputs = torch.randn(64, 1024)\n",
    "    outputs = model(inputs)\n",
    "\n",
    "# Set up the profiler\n",
    "lp = LineProfiler()\n",
    "lp.add_function(SimpleNN.forward)\n",
    "lp_wrapper = lp(profile_model)\n",
    "\n",
    "# Run the profiler\n",
    "lp_wrapper()\n",
    "lp.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840185ab-7aa1-4c12-a497-d99f4f641e8f",
   "metadata": {},
   "source": [
    "## Profiling is an essential part of optimizing ML/DL projects, ensuring that code runs efficiently and resources are used effectively. Tools like cProfile, memory_profiler, torch.cuda, timeit, and line_profiler provide different perspectives on performance, allowing you to identify and address bottlenecks in your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504ab3bb-83fc-4a2b-9383-4f66bbdf1749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edfd0f19-d2ee-4313-add3-f01134edc905",
   "metadata": {},
   "source": [
    "# Code Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b80c41f-042c-4c11-a7b5-76285ad96281",
   "metadata": {},
   "source": [
    "## What it is: Code tuning involves optimizing your code to improve performance, such as reducing execution time, memory usage, or improving model accuracy. In ML projects, this might include optimizing data pipelines, using more efficient algorithms, or tuning hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3091508b-1cbc-4886-9ffe-3d486d3a9ec6",
   "metadata": {},
   "source": [
    "# For ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a866e761-26ce-4c91-9c45-dba7ffbb1543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "#Before Tuning: Basic ML Model Training\n",
    "#This example uses the load_breast_cancer dataset from sklearn.datasets. The code loads the dataset, splits it into training and test sets, trains a RandomForestClassifier, and evaluates the model.\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f9d57db-67d8-4d4d-a3c3-cae5f859e64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Accuracy: 0.9649\n",
      "Best Parameters: {'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 10, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "#After Tuning: Optimized ML Model Training\n",
    "\n",
    "#Now, we'll apply code tuning techniques to improve the performance of the above code:\n",
    "\n",
    "#Optimizing Data Handling with Efficient Data Structures: Use NumPy arrays instead of Python lists for more efficient data handling.\n",
    "#Hyperparameter Tuning with RandomizedSearchCV: Use RandomizedSearchCV instead of default hyperparameters to find a more optimal configuration.\n",
    "#Parallel Processing with n_jobs: Utilize multiple CPU cores by setting n_jobs=-1 in the classifier and cross-validation.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convert to NumPy arrays for more efficient processing\n",
    "X_train, X_test = np.array(X_train), np.array(X_test)\n",
    "y_train, y_test = np.array(y_train), np.array(y_test)\n",
    "\n",
    "# Hyperparameter tuning using RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# RandomForest with parallel processing (n_jobs=-1)\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=10, cv=3, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train with RandomizedSearchCV\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model prediction and evaluation\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Optimized Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Best Parameters: {random_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41835f5c-2fa7-4464-8dd4-94212d0a45c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16cf414-e7c6-4d39-a5f7-a2767632d87c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43928671-f08b-4a66-bdc3-eb04c273063c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d90ec223-7208-4cd7-98ed-0713123128ca",
   "metadata": {},
   "source": [
    "# For DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "000313ee-235a-49b3-8503-bafcea3aeee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizing Data Loading and Preprocessing\n",
    "\n",
    "#Before Tuning:\n",
    "#Loading and preprocessing data can become a bottleneck, especially with large datasets. The code below loads data sequentially, which might be slow.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['new_feature'] = df['feature1'] * df['feature2']\n",
    "    df['normalized_feature'] = (df['feature1'] - df['feature1'].mean()) / df['feature1'].std()\n",
    "    return df\n",
    "\n",
    "#df = load_and_preprocess_data('large_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5df9d241-4ff4-406b-b81c-f93ee80f457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After Tuning:\n",
    "#Use chunking and vectorized operations to speed up data loading and preprocessing. Also, consider parallel processing if applicable.\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_preprocess_data(file_path, chunksize=100000):\n",
    "    chunks = []\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
    "        chunk['new_feature'] = chunk['feature1'] * chunk['feature2']\n",
    "        chunk['normalized_feature'] = (chunk['feature1'] - chunk['feature1'].mean()) / chunk['feature1'].std()\n",
    "        chunks.append(chunk)\n",
    "    df = pd.concat(chunks, axis=0)\n",
    "    return df\n",
    "\n",
    "#df = load_and_preprocess_data('large_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15308c-4187-4ae8-a579-6dade521b985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a8682e3-9eb2-48ea-8eca-1181ea0ddca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizing Model Training with Mixed Precision\n",
    "\n",
    "#Before Tuning:\n",
    "#Training deep learning models with single precision (32-bit floating-point) is common, but can be resource-intensive.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model = nn.Linear(1024, 512).cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for inputs, labels in dataloader:\n",
    "    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433b5201-287f-4fa3-933e-7eb348972259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After Tuning:\n",
    "#Mixed precision training (16-bit floating-point) can speed up training and reduce memory usage without sacrificing model accuracy.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "model = nn.Linear(1024, 512).cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()\n",
    "\n",
    "for inputs, labels in dataloader:\n",
    "    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    optimizer.zero_grad()\n",
    "    with autocast():\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11a58cd6-38c4-434d-94a0-3785f4eca557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizing Model Architecture\n",
    "#Before Tuning:\n",
    "#Using a complex model architecture with many layers and parameters can lead to slow training and inference times.\n",
    "import torch.nn as nn\n",
    "\n",
    "class ComplexModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplexModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 32)\n",
    "        self.fc6 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        return self.fc6(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ef304-1485-4497-b548-5c916479815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After Tuning:\n",
    "#Simplify the model architecture by reducing the number of layers or parameters, or using techniques like parameter sharing or pruning.\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class OptimizedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OptimizedModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(1024, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156707f8-9dae-417a-a488-45d952dbde9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizing Data Parallelism\n",
    "#Before Tuning:\n",
    "#Training on a single GPU can be slow, especially for large models and datasets.\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Linear(1024, 512).cuda()\n",
    "\n",
    "for inputs, labels in dataloader:\n",
    "    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2afb77-6e77-461f-be92-56222c213d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After Tuning:\n",
    "#Use data parallelism to distribute the training process across multiple GPUs.\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.parallel import DataParallel\n",
    "\n",
    "model = nn.Linear(1024, 512)\n",
    "model = DataParallel(model)\n",
    "model = model.cuda()\n",
    "\n",
    "for inputs, labels in dataloader:\n",
    "    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c5116-e6ec-4f2c-ad24-35790a890cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizing Hyperparameters with Grid Search or Random Search\n",
    "#Before Tuning:\n",
    "#Manually tuning hyperparameters is inefficient and can lead to suboptimal results.\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "model = nn.Linear(1024, 512)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19588406-8423-48b6-a8bf-b249ddb5fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After Tuning:\n",
    "#Use grid search or random search to systematically explore the hyperparameter space and find the optimal settings.\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "net = NeuralNetClassifier(model)\n",
    "params = {\n",
    "    'lr': [0.001, 0.01, 0.1],\n",
    "    'max_epochs': [10, 20, 30],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(net, params, refit=False, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best hyperparameters: {gs.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a2507-62bb-4007-98f9-a7d421c24ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizing I/O Operations\n",
    "\n",
    "#Before Tuning:\n",
    "#I/O operations, such as loading and saving models or checkpoints, can become a bottleneck if not optimized.\n",
    "\n",
    "import torch\n",
    "\n",
    "# Saving the model\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# Loading the model\n",
    "model.load_state_dict(torch.load('model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1ca465-48e7-494c-9e97-55db739a4da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After Tuning:\n",
    "#Use more efficient formats (like TorchScript for PyTorch) or compress the data to reduce I/O overhead.\n",
    "\n",
    "import torch\n",
    "\n",
    "# Saving the model with compression\n",
    "torch.save(model.state_dict(), 'model.pth', _use_new_zipfile_serialization=False)\n",
    "\n",
    "# Loading the model\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "\n",
    "# Alternatively, use TorchScript for faster loading\n",
    "scripted_model = torch.jit.script(model)\n",
    "torch.jit.save(scripted_model, 'scripted_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d197b1bb-ad8c-4124-8dc7-1deeb6d17f69",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Optimizing Batch Size\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#Before Tuning:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Using a default or arbitrarily chosen batch size might not be optimal for training performance.\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m      6\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "#Optimizing Batch Size\n",
    "#Before Tuning:\n",
    "#Using a default or arbitrarily chosen batch size might not be optimal for training performance.\n",
    "\n",
    "for inputs, labels in dataloader:\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556af898-6903-47f6-9e5b-952c5c038dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After Tuning:\n",
    "#Tune the batch size to maximize GPU utilization without causing memory overflow.\n",
    "\n",
    "batch_size = 64  # Increase or decrease based on profiling results\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for inputs, labels in dataloader:\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f5e0a9-7606-4c97-b6cd-e2bf2e176042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizing with Lazy Loading\n",
    "#Before Tuning:\n",
    "#Loading all data at once can be memory-intensive and slow.\n",
    "\n",
    "data = load_all_data()\n",
    "preprocessed_data = preprocess_data(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ea88f2-54a3-4100-9c2f-6448e6615ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After Tuning:\n",
    "#Use lazy loading to load data in chunks or only when needed.\n",
    "\n",
    "def load_data_in_chunks(file_path, chunksize=10000):\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunksize):\n",
    "        preprocessed_chunk = preprocess_data(chunk)\n",
    "        yield preprocessed_chunk\n",
    "\n",
    "for chunk in load_data_in_chunks('large_dataset.csv'):\n",
    "    # Process each chunk\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4df709e-3982-46ee-b7ed-b527df1d1968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9831e83f-7f0e-43a0-b1f1-8aa704b961c3",
   "metadata": {},
   "source": [
    "# Integration testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ba4d1c-6813-4bbd-8df7-e95b9a82748c",
   "metadata": {},
   "source": [
    "## Integration testing in machine learning (ML) projects involves testing the interaction between different components of the system to ensure they work together as expected. This could include testing data preprocessing, model training, and evaluation steps together as a pipeline. Hereâ€™s an example using a complete ML pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18e13ea0-fe01-4189-abc5-26d4716f8fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scenario: Integration Testing for an ML Pipeline\n",
    "\n",
    "#Let's consider an ML pipeline that includes the following steps:\n",
    "#Data Preprocessing: Scaling and transforming the input features.\n",
    "#Model Training: Training a classifier.\n",
    "#Model Evaluation: Evaluating the trained model on a test set.\n",
    "\n",
    "#We'll write an integration test to ensure that these components work together properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7673191-7c5a-430c-8328-179fc5a07c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 1.275s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import unittest\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the ML pipeline\n",
    "def create_ml_pipeline():\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Data Preprocessing\n",
    "        ('classifier', RandomForestClassifier(random_state=42))  # Model Training\n",
    "    ])\n",
    "    return pipeline\n",
    "\n",
    "class TestMLPipelineIntegration(unittest.TestCase):\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        # Load dataset\n",
    "        iris = load_iris()\n",
    "        cls.X_train, cls.X_test, cls.y_train, cls.y_test = train_test_split(\n",
    "            iris.data, iris.target, test_size=0.3, random_state=42\n",
    "        )\n",
    "        # Create pipeline\n",
    "        cls.pipeline = create_ml_pipeline()\n",
    "\n",
    "    def test_pipeline_training(self):\n",
    "        # Train the pipeline\n",
    "        self.pipeline.fit(self.X_train, self.y_train)\n",
    "        self.assertTrue(hasattr(self.pipeline.named_steps['classifier'], 'classes_'), \n",
    "                        \"Model training failed: 'classes_' attribute not found.\")\n",
    "\n",
    "    def test_pipeline_prediction(self):\n",
    "        # Train and predict\n",
    "        self.pipeline.fit(self.X_train, self.y_train)\n",
    "        y_pred = self.pipeline.predict(self.X_test)\n",
    "        accuracy = accuracy_score(self.y_test, y_pred)\n",
    "        \n",
    "        # Assert the accuracy is above a threshold\n",
    "        self.assertGreaterEqual(accuracy, 0.9, \"Model accuracy is below 0.9\")\n",
    "\n",
    "    def test_pipeline_inference(self):\n",
    "        # Train the pipeline\n",
    "        self.pipeline.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        # Test inference on a new sample\n",
    "        new_sample = [[5.1, 3.5, 1.4, 0.2]]  # A sample from the Iris dataset\n",
    "        prediction = self.pipeline.predict(new_sample)\n",
    "        \n",
    "        # Convert to Python int before checking type\n",
    "        prediction = int(prediction[0])\n",
    "        \n",
    "        # Assert the prediction is as expected (checking type and valid class label)\n",
    "        self.assertIsInstance(prediction, int, \"Prediction is not an integer class label.\")\n",
    "        self.assertIn(prediction, [0, 1, 2], \"Prediction is not a valid class label.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=[''], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c766b123-fc6d-403b-a8b5-e3a61c892291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb7db912-5498-49e1-937d-a8f59912af55",
   "metadata": {},
   "source": [
    "Here's a concise overview of Unit Testing, Integration Testing, Profiling, and Code Tuning in the context of machine learning, tailored for interview preparation:\r\n",
    "\r\n",
    "### **1. Unit Testing in ML/DL:**\r\n",
    "- **Definition:** Unit testing involves testing individual components or functions of a codebase to ensure they work correctly in isolation.\r\n",
    "- **Purpose:** To validate the correctness of each component (e.g., a specific data preprocessing function, a model training method).\r\n",
    "- **Example:** Testing a function that scales data or a model's predict method to ensure it returns outputs of the expected shape and type.\r\n",
    "- **Tools:** Pythonâ€™s `unittest`, `pytest`.\r\n",
    "\r\n",
    "### **2. Integration Testing in ML/DL:**\r\n",
    "- **Definition:** Integration testing checks the interaction between different components of the system to ensure they work together as intended.\r\n",
    "- **Purpose:** To validate that the end-to-end ML pipeline (e.g., data preprocessing, model training, and evaluation) functions correctly when integrated.\r\n",
    "- **Example:** Testing an entire ML pipeline where data is scaled, a model is trained, and predictions are made to ensure the workflow is seamless.\r\n",
    "- **Tools:** Pythonâ€™s `unittest`, `pytest`, with an emphasis on end-to-end tests.\r\n",
    "\r\n",
    "### **3. Profiling in ML/DL:**\r\n",
    "- **Definition:** Profiling is the process of measuring the performance of your code, identifying bottlenecks, and understanding resource usage (CPU, memory).\r\n",
    "- **Purpose:** To optimize the performance of ML models and preprocessing steps by identifying slow or resource-intensive parts of the code.\r\n",
    "- **Example:** Using a profiler like `cProfile` to measure the execution time of different parts of a training loop or feature engineering process.\r\n",
    "- **Tools:** `cProfile`, `line_profiler`, `memory_profiler`.\r\n",
    "\r\n",
    "### **4. Code Tuning in ML/DL:**\r\n",
    "- **Definition:** Code tuning refers to optimizing code for better performance, often by improving computational efficiency or reducing memory usage.\r\n",
    "- **Purpose:** To enhance the speed of ML model training/inference and reduce resource consumption, especially when working on CPUs.\r\n",
    "- **Example:** Optimizing the hyperparameters of a model, using efficient data structures (like NumPy arrays), and parallelizing computations.\r\n",
    "- **Techniques:** Vectorization, parallel processing (e.g., setting `n_jobs=-1`), efficient data handling.\r\n",
    "\r\n",
    "This summary provides a foundational understanding of key testing and optimization concepts relevant to machine learning, crucial for interview discussions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6141138a-4015-409f-823e-4db1325bb53c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
